{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress report: Unsupervised clustering of reads from two different sequences\n",
    "================================================================================\n",
    "\n",
    "\n",
    "A few months ago, I was assigned the task of clustering reads. This document sums my attempts to solve this problem, including the methods and thier results.\n",
    "\n",
    "Definition of the problem:\n",
    "--------------------------\n",
    "\n",
    "We have Fast5 files containing information, that includes the raw signal and the events, about reads coming from two different DNA sequences. Our goal is to cluster them using unsupervised methods. This means separating the reads into two groups according to the sequence they were generated from withut explicitly labeling them for the computer. This significantly Hardens the task, since the most successful machine learning algorithms to date have been supervised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First approach - Clustering via DTW\n",
    "-----------------------------------\n",
    "\n",
    "DTW (Dynamic Time Warping, [orignal text](https://www.aaai.org/Papers/Workshops/1994/WS-94-03/WS94-03-031.pdf)) is an algorithm that serves as a distance measure and creates an alignment between two time series. It is widely used in time series analysis, and hence has a multitude of variations and results based on it.\n",
    "\n",
    "Two give some intuition on how it works let us analyze this image:\n",
    "\n",
    "![title](https://ars.els-cdn.com/content/image/1-s2.0-S0169743916303732-gr2.jpg)\n",
    "\n",
    "DTW creates an aligment between the points of two time series (where a time series is defined is defined classicaly as $X(t)=[x_{0}, x_{1}...x_{n}]$ with $t(x_{n+1})-t(x_{n})=const$ ) such as the sum of the distance of the aligned point is the minimum.\n",
    "This means the DTW take into account phase shifts and two a certain extent amplitude and length difference between the time serieses, as we can see above. This makes it theoritically suitable to be used on our messy time series data.\n",
    "\n",
    "The known approach to clustering time series based on DTW is DBA (DTW Barycenter Averaging [original text](https://www.researchgate.net/publication/220601732_A_global_averaging_method_for_dynamic_time_warping_with_applications_to_clustering)) which is effectively the K-means algorithm using DTW. However this technique relies on same length time series, which we dont have. It is possible to solve this by interlopating the time series as shown by this paper on DTW qualities: [paper]().\n",
    "\n",
    "Implementation:\n",
    "---------------\n",
    "\n",
    "I have knowledge in programming python, so that was my language of focus. There is one significant time series package called tslearn, which has a DBA function built in. However I found their implementation two slow, as it took about eight hours two finish running on 40 raw signals total, 20 from each sequence. In addition, the results were inconclusive, as the prediction were as good as guessing. I set on programming an more efficient implementation. I did so with these methods:\n",
    "\n",
    "1. Use FasDTW instead of DTW. FastDTW ([original paper](https://pdfs.semanticscholar.org/05a2/0cde15e172fc82f32774dd0cf4fe5827cad2.pdf)) is an algorithm which approximates DTW with $O(n)$ time complexity instead of $O(n^2)$.\n",
    "\n",
    "2. Using packages that speed up python. Not mentioning the obvious tool for numerical computing that is numpy, there also two important option for *compiling* python, even though it is an interpeted language. The first option is Cython, not to be confused with Cpython, which is a superset of python that allows compiling python to c files and allows for C like syntax to make the compiling more efficient. The second one is numba, which is a jit (just in time) compiler for python based on [llvm](https://llvm.org/). It's syntax is easier than Cython, however it is harder to debug sometimes and I recommend it only for relatively short code.  \n",
    "\n",
    "3. Using a fast cython based implementaion of FastDTW in python called fastdtw.\n",
    "\n",
    "I wrote a version based on numba, cython, and normal python and cython. On average, the python version is the fastest version however I'm sure more can be done to improve the other versions.\n",
    "In total this manged to speed up the program by 20 to 40 to times over the original, which also used cython and numpy. This is comparable to c speeds. This is the code and documentation for the python version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastdtw import fastdtw\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tslearn.barycenters import dtw_barycenter_averaging\n",
    "from tslearn.preprocessing import TimeSeriesResampler\n",
    "from sklearn.cluster.k_means_ import _k_init\n",
    "from sklearn.utils import check_random_state\n",
    "import timeit\n",
    "import time\n",
    "\n",
    "def medoid(D):\n",
    "    '''\n",
    "    Find medoid of database D, which is an ndarray, each row is a timeseries. does so in O(n^2)\n",
    "    '''\n",
    "    \n",
    "    #compute distance matrix\n",
    "    n=D.shape[0]\n",
    "    dist_matrix=np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1):\n",
    "            #t1=time.perf_counter()\n",
    "            dist_matrix[i,j]=fastdtw(D[i],D[j])[0]\n",
    "            #print (time.perf_counter()-t1)\n",
    "    dist_matrix=np.maximum(dist_matrix,dist_matrix.T)\n",
    "\n",
    "    #check for mediod\n",
    "    med=D[np.argmin(np.sum(dist_matrix,axis=1))]\n",
    "    return med\n",
    "\n",
    "def s_contrib(center,s):\n",
    "    '''\n",
    "    Contribution of timeseries/signal s to barycenter center. Works with FDBA_update, as the center_matrix is the sum of all contributions.\n",
    "    '''\n",
    "\n",
    "    alignment=np.array(fastdtw(center,s)[1])\n",
    "    contrib=np.zeros((center.shape[0],2))\n",
    "\n",
    "    for i in range(center.shape[0]):\n",
    "        i_contrib=alignment[alignment[:,0]==i][:,1]\n",
    "        contrib[i,0]=np.sum(s[i_contrib])\n",
    "        contrib[i,1]=i_contrib.shape[0]\n",
    "\n",
    "    return contrib\n",
    "\n",
    "def FDBA_update(center_matrix):\n",
    "    '''\n",
    "    Update barycenter according to the center_matrix. The center_matrix is an ndarray with shape=(2,length of center), the barycenter is calculated\n",
    "    as center[i]=center_matrix[0]/center_matrix[1]\n",
    "    '''\n",
    "    \n",
    "    return np.divide(center_matrix[:,0],center_matrix[:,1])\n",
    "\n",
    "def FDBA(D,n_iterations=10,verbose=False):\n",
    "    '''\n",
    "    Fast DTW barycenter averaging full algorithm. n_iteration tells how many times to update center. If verbose is True, \n",
    "    prints number of current iteration.\n",
    "    '''\n",
    "    center=medoid(D)#initializing center as mediod\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        if verbose:\n",
    "            print (\"FDBA iteration: \"+str(i+1))\n",
    "        new_center=np.zeros((center.shape[0],2))\n",
    "        for s in D:\n",
    "            new_center=np.add(new_center,s_contrib(center,s))\n",
    "        center=FDBA_update(new_center)\n",
    "\n",
    "    return center\n",
    "\n",
    "def assign(centers,D):\n",
    "    '''\n",
    "    Assigns labels to timeseries in D according to barycenters centers, kmeans style, with distance metric FDTW. \n",
    "    '''\n",
    "    dists=np.zeros((D.shape[0],centers.shape[0]))\n",
    "\n",
    "    for i in range(D.shape[0]):\n",
    "        for j in range(centers.shape[0]):\n",
    "            dists[i,j]=fastdtw(D[i],centers[j])[0]\n",
    "    matched_labels=dists.argmin(axis=1)\n",
    "\n",
    "    return matched_labels\n",
    "\n",
    "def FDBA_clustering(D,n_iterations=10,k=2,verbose=False):\n",
    "    '''\n",
    "    Full algorithm. D is an jagged ndarray, representing different length time series. n_iteration tells how many times to update center. k is the\n",
    "    number of barycenters. If verbose is True, prints number of current iteration.\n",
    "    '''\n",
    "    sz=np.max(np.array(list(map(lambda s: len(s),D))))\n",
    "    D=TimeSeriesResampler(sz=sz).fit_transform(D)\n",
    "    D=np.squeeze(D)\n",
    "    D_squared_norms=(D * D).sum(axis=1)\n",
    "    centers=_k_init(D,k,D_squared_norms,check_random_state(None))\n",
    "\n",
    "    for i in range(n_iterations):\n",
    "        if verbose:\n",
    "            print (\"Clustering iteration: \"+str(i+1))\n",
    "        matched_labels=assign(centers,D)\n",
    "        for j in range(len(centers)):\n",
    "            centers[j]=FDBA(D[matched_labels==j],verbose=verbose)\n",
    "\n",
    "    return centers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:\n",
    "-------\n",
    "\n",
    "After running the program 3 days straight on 120 raw signals, evenly split between the sequences, the results where not good at all, as seen in these cells:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "import os\n",
    "from dtw_stuff import FDBA as fdba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading 30 signals from each directory. Each directory contains 30 reads from passes and fail's of both barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#30 files in each pass fail\n",
    "\n",
    "t1=[]#barcode2 signals\n",
    "t2=[]#barcode2 signals\n",
    "\n",
    "path1='./Fast5_files_30_each/pass/barcode1'\n",
    "path2='./Fast5_files_30_each/fail/barcode1'\n",
    "path3='./Fast5_files_30_each/pass/barcode2'\n",
    "path4='./Fast5_files_30_each/fail/barcode2'\n",
    "\n",
    "def find_read(name):\n",
    "    #Find all Signals\n",
    "    if 'Signal' in name:\n",
    "        return 'Raw/Reads/'+name\n",
    "\n",
    "for name in os.listdir(path1):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path1,name),'r')\n",
    "        t1.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "    \n",
    "for name in os.listdir(path2):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path2,name),'r')\n",
    "        t1.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "\n",
    "for name in os.listdir(path3):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path3,name),'r')\n",
    "        t2.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "\n",
    "for name in os.listdir(path4):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path4,name),'r')\n",
    "        t2.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "\n",
    "D1=np.array(t1)\n",
    "D2=np.array(t2)\n",
    "D=np.array(t1+t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7781ec2a4e344c97aa43d3d43112032a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for s in D1:\n",
    "    plt.plot(range(s.shape[0]),s)\n",
    "\n",
    "plt.title(\"Current of signal as a function of the measurment for barcode1\")\n",
    "plt.xlabel(\"Number of measurement\")\n",
    "plt.ylabel(\"Signal current\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4e4e755ab424e56a82c5d7c13818b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for s in D2:\n",
    "    plt.plot(range(s.shape[0]),s)\n",
    "\n",
    "plt.title(\"Current of signal as a function of the measurment for barcode2\")\n",
    "plt.xlabel(\"Number of measurement\")\n",
    "plt.ylabel(\"Signal current\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c46a4a46c05e41d59f81d12fa99a660a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "for s in D:\n",
    "    plt.plot(range(s.shape[0]),s)\n",
    "\n",
    "plt.title(\"Current of signal as a function of the measurment for both barcodes\")\n",
    "plt.xlabel(\"Number of measurement\")\n",
    "plt.ylabel(\"Signal current\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the centers that are the result of FDBA on data from hardrive, and assigning labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers=np.loadtxt(\"centers.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 0 0 1 1 1 1 0 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 0 1 1 1 0 1 1 0 1 1 1 1 0 0 0 1 1 0 1 0\n",
      " 0 1 1 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1\n",
      " 0 1 0 1 0 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "labels=fdba.assign(centers,D)#just wrong, supposed to be all ones and then all zeros or vice-versa\n",
    "print (labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "-----------\n",
    "\n",
    "I'm not sure this technique doesnt work, considering the I only tried clustering 120 signals at once, and the fact that maybe running the code longer would have created better results, however i dont think this is the right approach, since even with a significant speedup of the code with pararell computing and a rewrite in efficient c, to cluster large clusters of hundred of reads you would need a lot of time to iterate over the code. The most important take away is the need to work with the data in a way that wont require heavy computational work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data\n",
    "------------------\n",
    "One way of avoiding the heavy computational work is to extract features from the time serieses, for example mean of the time series, and work with that.\n",
    "In accordance to this, I was asked to create histograms of the event means of the reads. Here are the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "#event important things: mean is in position 0, var in position 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading all events from each directory. Each directory contains reads from passes and fail's of both barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All events on fast5 files on computer\n",
    "\n",
    "t1=[]#barcode2 reads\n",
    "t2=[]#barcode2 reads\n",
    "\n",
    "path1='./Fast5_files/pass/barcode1'\n",
    "path2='./Fast5_files/fail/barcode1'\n",
    "path3='./Fast5_files/pass/barcode2'\n",
    "path4='./Fast5_files/fail/barcode2'\n",
    "\n",
    "for name in os.listdir(path1):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path1,name),'r')\n",
    "        t1.append(np.array(f.get('/Analyses/Basecall_1D_001/BaseCalled_template/Events')))\n",
    "    \n",
    "for name in os.listdir(path2):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path2,name),'r')\n",
    "        t1.append(np.array(f.get('/Analyses/Basecall_1D_001/BaseCalled_template/Events')))\n",
    "\n",
    "for name in os.listdir(path3):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path3,name),'r')\n",
    "        t2.append(np.array(f.get('/Analyses/Basecall_1D_001/BaseCalled_template/Events')))\n",
    "\n",
    "for name in os.listdir(path4):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path4,name),'r')\n",
    "        t2.append(np.array(f.get('/Analyses/Basecall_1D_001/BaseCalled_template/Events')))\n",
    "\n",
    "D1=np.array(t1)\n",
    "D2=np.array(t2)\n",
    "D=np.array(t1+t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for consistent graphs\n",
    "\n",
    "xmin,xmax=50,180\n",
    "ymin,ymax=0,0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting event means \n",
    "\n",
    "event_means1=[]\n",
    "event_means2=[]\n",
    "\n",
    "for read in D1:\n",
    "    means=[]\n",
    "    for j in range(read.shape[0]):\n",
    "            means.append(read[j][0])\n",
    "    event_means1.append(np.array(means))\n",
    "\n",
    "for read in D2:\n",
    "    means=[]\n",
    "    for j in range(read.shape[0]):\n",
    "            means.append(read[j][0])\n",
    "    event_means2.append(np.array(means))\n",
    "    \n",
    "event_means1=np.array(event_means1)\n",
    "event_means2=np.array(event_means2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae45129dd574d9384db0cbb4c440eba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_events1=np.hstack(event_means1)\n",
    "#normed_data,xmin_t,xmax_t=norm_pdf_hist(flat_events1,bins=1000,xlims=(xmin,xmax)) remember to change to normed_data\n",
    "plt.hist(flat_events1,bins=1000, density=True,color='orange')\n",
    "plt.title(\"Histogram of mean current of events from barcode1\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Mean current of single event')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be74af81a15d4e1a826621cb0deccd26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "event_means2=np.array(event_means2)\n",
    "fig=plt.figure()\n",
    "flat_events2=np.hstack(event_means2)\n",
    "#normed_data,xmin_t,xmax_t=norm_pdf_hist(flat_events2,bins=1000,xlims=(xmin,xmax)) remember to change to normed_data\n",
    "plt.hist(flat_events2,bins=1000, density=True)\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Histogram of mean current of events from barcode2\")\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Mean current of single event')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c0a0f66fda41bca2d00a499c40dc6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "o1=plt.hist(flat_events1,bins=1000,density=True,histtype=u'step',label='barcode1',color='orange')\n",
    "o2=plt.hist(flat_events2,bins=1000,density=True,histtype=u'step',label='barcode2')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Histogram of mean current of events from barcode2 and barcode1\")\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Mean current of single event')\n",
    "plt.legend(('barcode2','barcode1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it is possible to see, the histograms look like normal distributions however they have different skewedness and kurtosis ([third and fourth moments](https://en.wikipedia.org/wiki/Moment_(mathematics)). I tried to cluster the reads by fitting a distribution characterized by the mean, variance and skewedness ([as defined here](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.skewnorm.html)) to the event means of a read and then applying K-means. It didn't work.\n",
    "\n",
    "To understand why i created these interactive plots:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "661abf72418949678d248db524936cfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85fd6f3b5e3f436499f6ed105aee0fb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='i', max=760, min=1), IntSlider(value=1, description='t',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "def f(i,t):\n",
    "    plt.cla()\n",
    "    events=event_means1[i-1]\n",
    "    plt.hist(events[:t],bins=1000,density=True,color='orange')\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(ymin,ymax)\n",
    "    plt.title(\"Histogram of mean current of events from read i in barcode1 until read t\")\n",
    "    plt.ylabel('Probability density')\n",
    "    plt.xlabel('Mean current of single event')\n",
    "\n",
    "i_widget=widgets.IntSlider(min=1,max=event_means1.shape[0],step=1,value=1)\n",
    "t_widget=widgets.IntSlider(min=1,max=event_means1[0].shape[0],step=100,value=1)\n",
    "\n",
    "def update_t_range(*args):\n",
    "    t_widget.max = event_means1[i_widget.value-1].shape[0]\n",
    "    \n",
    "i_widget.observe(update_t_range, 'value')\n",
    "\n",
    "interact(f,i=i_widget,t=t_widget)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47751fd7f3444130bd04b882accaef23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01fb461ece9849cc8f7e6c694d08d229",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='i', max=757, min=1), IntSlider(value=1, description='t',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "def f(i,t):\n",
    "    plt.cla()\n",
    "    events=event_means2[i-1]\n",
    "    plt.hist(events[:t],bins=1000,density=True)\n",
    "    plt.xlim(xmin,xmax)\n",
    "    plt.ylim(ymin,ymax)\n",
    "    plt.title(\"Histogram of mean current of events from read i in barcode2 until read t\")\n",
    "    plt.ylabel('Probability density')\n",
    "    plt.xlabel('Mean current of single event')\n",
    "\n",
    "i_widget=widgets.IntSlider(min=1,max=event_means2.shape[0],step=1,value=1)\n",
    "t_widget=widgets.IntSlider(min=1,max=event_means2[0].shape[0],step=100,value=1)\n",
    "\n",
    "def update_t_range(*args):\n",
    "    t_widget.max = event_means2[i_widget.value-1].shape[0]\n",
    "    \n",
    "i_widget.observe(update_t_range, 'value')\n",
    "\n",
    "interact(f,i=i_widget,t=t_widget)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can be seen that the histograms vary a lot between each read, hence the method wasn't effective.\n",
    "I did the same for variance of event means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting variance of events\n",
    "\n",
    "event_variance1=[]\n",
    "event_variance2=[]\n",
    "\n",
    "for read in D1:\n",
    "    means=[]\n",
    "    for j in range(read.shape[0]):\n",
    "            means.append(read[j][0])\n",
    "    event_variance1.append(np.var(means))\n",
    "\n",
    "for read in D2:\n",
    "    means=[]\n",
    "    for j in range(read.shape[0]):\n",
    "            means.append(read[j][0])\n",
    "    event_variance2.append(np.var(means))\n",
    "    \n",
    "event_variance1=np.array(event_variance1)\n",
    "event_variance2=np.array(event_variance2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for consistent graphs\n",
    "\n",
    "xmin,xmax=110,200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd90c179b6b540569dec4260262fef98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_events1=np.hstack(event_variance1)\n",
    "plt.hist(flat_events1,bins=100, density=True,color='orange')\n",
    "plt.title(\"Histogram of variance of current of reads from barcode1\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Variance of current of single read')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c8c19a32314824a643d34467731cf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_events2=np.hstack(event_variance2)\n",
    "plt.hist(flat_events2,bins=100, density=True)\n",
    "plt.title(\"Histogram of variance of current of reads from barcode2\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Variance of current of single read')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_outlier(points, thresh=3.5):\n",
    "    \"\"\"\n",
    "    Returns a boolean array with True if points are outliers and False \n",
    "    otherwise.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "        points : An numobservations by numdimensions array of observations\n",
    "        thresh : The modified z-score to use as a threshold. Observations with\n",
    "            a modified z-score (based on the median absolute deviation) greater\n",
    "            than this value will be classified as outliers.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "        mask : A numobservations-length boolean array.\n",
    "\n",
    "    References:\n",
    "    ----------\n",
    "        Boris Iglewicz and David Hoaglin (1993), \"Volume 16: How to Detect and\n",
    "        Handle Outliers\", The ASQC Basic References in Quality Control:\n",
    "        Statistical Techniques, Edward F. Mykytka, Ph.D., Editor. \n",
    "    \"\"\"\n",
    "    if len(points.shape) == 1:\n",
    "        points = points[:,None]\n",
    "    median = np.median(points, axis=0)\n",
    "    diff = np.sum((points - median)**2, axis=-1)\n",
    "    diff = np.sqrt(diff)\n",
    "    med_abs_deviation = np.median(diff)\n",
    "\n",
    "    modified_z_score = 0.6745 * diff / med_abs_deviation\n",
    "\n",
    "    return modified_z_score > thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0740f19fc1334ea7888d5b37c824dd79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_events1=np.hstack(event_variance1)\n",
    "filtered1=flat_events1[~is_outlier(flat_events1)]\n",
    "plt.hist(filtered1,bins=100, density=True,color='orange')\n",
    "plt.title(\"Histogram with filtering of variance of current of reads from barcode1\")\n",
    "#plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Variance of current of single read')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a2b0749d7f449419d33712c53c7d783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_events2=np.hstack(event_variance2)\n",
    "filtered2=flat_events2[~is_outlier(flat_events2)]\n",
    "plt.hist(filtered2,bins=100, density=True)\n",
    "plt.title(\"Histogram with filtering of variance of current of reads from barcode2\")\n",
    "#plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Variance of current of single read')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69bece85147244d7825430f24397e1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "o1=plt.hist(filtered1,bins=100,density=True,histtype=u'step',label='barcode1',color='orange')\n",
    "o2=plt.hist(filtered2,bins=100,density=True,histtype=u'step',label='barcode2')\n",
    "#plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Histogram of mean current of events from barcode2 and barcode1\")\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Mean current of single event')\n",
    "plt.legend(('barcode2','barcode1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the raw signal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading signals from each directory. Each directory contains reads from passes and fail's of both barcodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All signals on fast5 files on computer\n",
    "\n",
    "t1=[]#barcode2 signals\n",
    "t2=[]#barcode2 signals\n",
    "\n",
    "path1='./Fast5_files/pass/barcode1'\n",
    "path2='./Fast5_files/fail/barcode1'\n",
    "path3='./Fast5_files/pass/barcode2'\n",
    "path4='./Fast5_files/fail/barcode2'\n",
    "\n",
    "def find_read(name):\n",
    "    #Find all Signals\n",
    "    if 'Signal' in name:\n",
    "        return 'Raw/Reads/'+name\n",
    "\n",
    "for name in os.listdir(path1):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path1,name),'r')\n",
    "        t1.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "    \n",
    "for name in os.listdir(path2):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path2,name),'r')\n",
    "        t1.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "\n",
    "for name in os.listdir(path3):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path3,name),'r')\n",
    "        t2.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "\n",
    "for name in os.listdir(path4):\n",
    "    if name!='.ipynb_checkpoints':\n",
    "        f=h5py.File(os.path.join(path4,name),'r')\n",
    "        t2.append(np.array(f.get(f.get('Raw/Reads').visit(find_read))))\n",
    "\n",
    "S1=np.array(t1)\n",
    "S2=np.array(t2)\n",
    "S=np.array(t1+t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for consistent graphs\n",
    "\n",
    "xmin,xmax=200,600\n",
    "ymin,ymax=0,0.02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c1b116f3fe4d88b8d95e7183bed9dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_S1=np.hstack(S1)\n",
    "plt.hist(flat_S1,bins=4095, density=True,color='orange')#check with them wtf is happening with bins\n",
    "plt.title(\"Histogram of signals from barcode1\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57120b65536a4476bc7277902ce69bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_S2=np.hstack(S2)\n",
    "plt.hist(flat_S2,bins=4095, density=True)#check with them wtf is happening with bins\n",
    "plt.title(\"Histogram of signals from barcode2\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8d67d70643491ea0ab539132b88d46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_S1=np.hstack(S1)\n",
    "filtered1=flat_S1[~is_outlier(flat_S1)]\n",
    "plt.hist(filtered1,bins=475, density=True,color='orange')\n",
    "plt.title(\"Histogram of signals from barcode1\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02295f5133f34369aca692bd2388aaca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "flat_S2=np.hstack(S2)\n",
    "filtered2=flat_S2[~is_outlier(flat_S2)]\n",
    "plt.hist(filtered1,bins=475, density=True)\n",
    "plt.title(\"Histogram of signals from barcode2\")\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c574df92a1242a1b9a2dfd170925d81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig=plt.figure()\n",
    "plt.hist(filtered1,bins=475,density=True,histtype=u'step',label='barcode1',color='orange')\n",
    "plt.hist(filtered2,bins=475,density=True,histtype=u'step',label='barcode2')\n",
    "plt.xlim(xmin,xmax)\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Histogram of signals from barcode2 and barcode1\")\n",
    "plt.ylabel('Probability density')\n",
    "plt.xlabel('Signal')\n",
    "plt.legend(('barcode2','barcode1'))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Second approach - Extracting features\n",
    "-------------------------------------\n",
    "\n",
    "After realizing that examining features one by one is a waste of time, I used the python package [tsfresh](https://tsfresh.readthedocs.io/en/latest/text/introduction.html) to extract 789 features who aren't computaitionally heavy ([detailed here](https://tsfresh.readthedocs.io/en/latest/api/tsfresh.feature_extraction.html)). After calclulating the features, I tried clustering them with various algorithms (listed below) with above average but not sufficient success.\n",
    "\n",
    "Implementation and Results:\n",
    "------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.cluster import KMeans,DBSCAN,SpectralClustering\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy.spatial import distance_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extracting the features (Do not run, takes long time):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids1=[]\n",
    "ids2=[]\n",
    "\n",
    "for i in range(S1.shape[0]):\n",
    "    ids1.append(np.full(S1[i].shape[0],i))\n",
    "    \n",
    "for i in range(S2.shape[0]):\n",
    "    ids2.append(np.full(S2[i].shape[0],i))\n",
    "\n",
    "ids1=np.concatenate(ids1)\n",
    "ids2=np.concatenate(ids2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "time1=[]\n",
    "time2=[]\n",
    "\n",
    "for s in S1:\n",
    "    time1.append(np.arange(s.shape[0]))\n",
    "    \n",
    "for s in S2:\n",
    "    time2.append(np.arange(s.shape[0]))\n",
    "    \n",
    "time1=np.concatenate(time1)\n",
    "time2=np.concatenate(time2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "S1_df=pd.DataFrame({'id':ids1,\n",
    "                    'Time':time1,\n",
    "                    'Signal':flat_S1})\n",
    "\n",
    "S2_df=pd.DataFrame({'id':ids2,\n",
    "                    'Time':time2,\n",
    "                    'Signal':flat_S2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['id', 'Time', 'Signal'], dtype='object'),\n",
       " Index(['id', 'Time', 'Signal'], dtype='object'))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S1_df.columns,S2_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "extraction_settings = tsfresh.feature_extraction.EfficientFCParameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [2:29:56<00:00, 665.73s/it]\n"
     ]
    }
   ],
   "source": [
    "features1 = tsfresh.extract_features(S1_df, \n",
    "                     column_id='id', column_sort='Time',\n",
    "                     default_fc_parameters=extraction_settings,\n",
    "                     impute_function=tsfresh.utilities.dataframe_functions.impute\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|██████████| 10/10 [2:46:39<00:00, 936.52s/it]\n"
     ]
    }
   ],
   "source": [
    "features2 = tsfresh.extract_features(S2_df, \n",
    "                     column_id='id', column_sort='Time',\n",
    "                     default_fc_parameters=extraction_settings,\n",
    "                     impute_function=tsfresh.utilities.dataframe_functions.impute\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the features (Do not run, unless your sure you want to save features as they currently are):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features1.to_csv('./Features1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features2.to_csv('./Features2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the saved features from memory, and turning them into easy to work with ndarray:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "features1=pd.read_csv('./Features1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "features2=pd.read_csv('./Features2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((760, 789), (757, 789))"
      ]
     },
     "execution_count": 300,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1.shape,features2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "F=np.vstack((features1.values,features2.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating the [scaled](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html) data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2=StandardScaler()\n",
    "\n",
    "scaler2.fit(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaled_F=scaler.fit_transform(F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating means of scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_mean1=np.mean(scaled_F[:760],axis=0)\n",
    "scaled_mean2=np.mean(scaled_F[760:],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01ff0bc1e9494a8a83d4a6628f6eaefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Feature amplitude as a function of number of features\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(np.broadcast_to(np.arange(F.shape[1]),(760,F.shape[1])),F[:760],'C1.',alpha=0.4)\n",
    "plt.plot(np.broadcast_to(np.arange(F.shape[1]),(757,F.shape[1])),F[760:],'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27227f95de70464e9cf10e279c073ba6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Scaled feature amplitude as a function of number of features\")\n",
    "plt.ylabel(\"Scaled feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(np.broadcast_to(np.arange(scaled_F.shape[1]),(760,scaled_F.shape[1])),scaled_F[:760],'C1.',alpha=0.4)\n",
    "plt.plot(np.broadcast_to(np.arange(scaled_F.shape[1]),(757,scaled_F.shape[1])),scaled_F[760:],'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1503fb04a011407997bcdb01ab86c674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"The mean of the scaled feature amplitude's\")\n",
    "plt.ylabel(\"Scaled feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) on normal data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans=KMeans(n_clusters=2)\n",
    "\n",
    "kmeans.fit(F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 3.80714286e+02, -2.98492714e+07,  3.93892649e+05, ...,\n",
       "         0.00000000e+00,  2.42519171e+03,  1.00000000e+00],\n",
       "       [ 3.77247963e+02,  1.31966071e+07,  3.12138923e+05, ...,\n",
       "         0.00000000e+00,  2.45447766e+03,  1.00000000e+00]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of prediction in probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6381578947368421 0.5059445178335535\n"
     ]
    }
   ],
   "source": [
    "prob1=np.sum(kmeans.predict(F[:760]))/760\n",
    "prob2=1-np.sum(kmeans.predict(F[760:]))/757\n",
    "\n",
    "if (prob1+prob2)>=(2-prob1-prob2):\n",
    "    print (prob1,prob2)\n",
    "else:\n",
    "    print (1-prob1,1-prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting K-means centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea86001ba46049c89aa1b2485ae0bc30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Kmean centers of unscaled feature's\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(kmeans.cluster_centers_.shape[1]),kmeans.cluster_centers_[0],'C1.')\n",
    "plt.plot(range(kmeans.cluster_centers_.shape[1]),kmeans.cluster_centers_[1],'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[K-means](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html) on scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_kmeans=KMeans(n_clusters=2)\n",
    "scaled_kmeans.fit(scaled_F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.21569064,  0.10971594, -1.20847805, ...,  0.        ,\n",
       "         0.24700268,  0.        ],\n",
       "       [-0.08868397, -0.04511111,  0.49688121, ...,  0.        ,\n",
       "        -0.10155831,  0.        ]])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of prediction in probabilities, and finding corresponding centers to groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.33947368421052626 0.7569352708058125\n"
     ]
    }
   ],
   "source": [
    "center1=None\n",
    "center2=None\n",
    "\n",
    "prob1=np.sum(scaled_kmeans.predict(scaled_F[:760]))/760\n",
    "prob2=1-np.sum(scaled_kmeans.predict(scaled_F[760:]))/757\n",
    "\n",
    "if (prob1+prob2)>=(2-prob1-prob2):\n",
    "    print (prob1,prob2)\n",
    "    center1=scaled_kmeans.cluster_centers_[1]\n",
    "    center2=scaled_kmeans.cluster_centers_[0]\n",
    "else:\n",
    "    print (1-prob1,1-prob2)\n",
    "    center1=scaled_kmeans.cluster_centers_[0]\n",
    "    center2=scaled_kmeans.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for consistent graphs\n",
    "\n",
    "ymin,ymax=-1.4,1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21053f8dfff4d6ba46ce51ddad99150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Kmean centers of scaled feature's\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'C1.',alpha=0.4)\n",
    "plt.plot(range(center2.shape[0]),center2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcbee27d431452a9aa9585688795ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Kmean centers compared to means of unscaled feature's\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center2.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2c785a6bbc4ce8970d2fcd94d51138",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Kmean center compared to mean of unscaled feature's barcode1\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4488e3f74cc143e6998957421df7e1da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Kmean center compared to mean of unscaled feature's barcode2\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[DBscan](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.DBSCAN.html), an unsupervised clustering algorithm based on finding dense clusters and the \"vacums\" between them, on scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DBSCAN(algorithm='auto', eps=25, leaf_size=30, metric='euclidean',\n",
       "    metric_params=None, min_samples=5, n_jobs=1, p=None)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dbscan=DBSCAN(eps=25)\n",
    "dbscan.fit(scaled_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of prediction in probabilities, and calculating corresponding centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.668421052631579 0.7093791281373845\n"
     ]
    }
   ],
   "source": [
    "center1=None\n",
    "center2=None\n",
    "\n",
    "prob1=np.sum(dbscan.labels_[:760])/760*-1\n",
    "prob2=1-np.sum(dbscan.labels_[760:])/757*-1\n",
    "\n",
    "if (prob1+prob2)>=(2-prob1-prob2):\n",
    "    print (prob1,prob2)\n",
    "    center1=np.mean(scaled_F[dbscan.labels_==1],axis=0)\n",
    "    center2=np.mean(scaled_F[dbscan.labels_==0],axis=0)\n",
    "else:\n",
    "    print (1-prob1,1-prob2)\n",
    "    center1=np.mean(scaled_F[dbscan.labels_==0],axis=0)\n",
    "    center2=np.mean(scaled_F[dbscan.labels_==-1],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for consistent graphs\n",
    "\n",
    "ymin,ymax=-1.4,1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6a2cd7fb777448a9091941e019a1482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"DBscan means of scaled feature's groups\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'C1.',alpha=0.4)\n",
    "plt.plot(range(center2.shape[0]),center2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a8437a17874907b60a29d92b09f388",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"DBscan means compared to means of unscaled feature's\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center2.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da0dce6489534433ba8ad653321631e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"DBscan mean compared to mean of unscaled feature's barcode1\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60e207ced65a4a35aeb1e32fa749175e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"DBscan compared to mean of unscaled feature's barcode2\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Spectral clustering](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.SpectralClustering.html#sklearn.cluster.SpectralClustering), didnt find intuition for the algorithm, on scaled data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\sklearn\\manifold\\spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SpectralClustering(affinity='rbf', assign_labels='kmeans', coef0=1, degree=3,\n",
       "          eigen_solver=None, eigen_tol=0.0, gamma=1.0, kernel_params=None,\n",
       "          n_clusters=2, n_init=10, n_jobs=1, n_neighbors=10,\n",
       "          random_state=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spectral=SpectralClustering(n_clusters=2)\n",
    "spectral.fit(scaled_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of prediction in probabilities, and calculating corresponding centers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9605263157894737 0.15719947159841485\n"
     ]
    }
   ],
   "source": [
    "center1=None\n",
    "center2=None\n",
    "\n",
    "prob1=np.sum(spectral.labels_[:760])/760\n",
    "prob2=1-np.sum(spectral.labels_[760:])/757\n",
    "\n",
    "if (prob1+prob2)>=(2-prob1-prob2):\n",
    "    print (prob1,prob2)\n",
    "    center1=np.mean(scaled_F[spectral.labels_==1],axis=0)\n",
    "    center2=np.mean(scaled_F[spectral.labels_==0],axis=0)\n",
    "else:\n",
    "    print (1-prob1,1-prob2)\n",
    "    center1=np.mean(scaled_F[spectral.labels_==0],axis=0)\n",
    "    center2=np.mean(scaled_F[spectral.labels_==1],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters for consistent graphs\n",
    "\n",
    "ymin,ymax=-1.4,1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c68978f19da842228df7ee139d79dfd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Spectral clustering means of scaled feature's groups\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'C1.',alpha=0.4)\n",
    "plt.plot(range(center2.shape[0]),center2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "393fcc469a6e4195a2614a1ca3ca0838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Spectral clustering means compared to means of unscaled feature's\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center2.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8d87ff494cd4697962b570d0eb54a4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Spectral clustering mean compared to mean of unscaled feature's barcode1\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean1.shape[0]),scaled_mean1,'C1.',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65242d43c16f40439234dabdd9283454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.ylim(ymin,ymax)\n",
    "plt.title(\"Spectral clustering to mean of unscaled feature's barcode2\")\n",
    "plt.ylabel(\"Feature amplitude\")\n",
    "plt.xlabel(\"Number of feature\")\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(scaled_mean2.shape[0]),scaled_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "------------\n",
    "\n",
    "We see these algorithms have an okay accuracy when applied on the features extracted from the signals, specifically DBscan.\n",
    "In addition, we see the main difference between the groups in these parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Signal__fft_aggregated__aggtype_\"centroid\"',\n",
       "       'Signal__fft_aggregated__aggtype_\"kurtosis\"',\n",
       "       'Signal__fft_aggregated__aggtype_\"skew\"',\n",
       "       'Signal__fft_aggregated__aggtype_\"variance\"',\n",
       "       'Signal__fft_coefficient__coeff_0__attr_\"abs\"',\n",
       "       'Signal__fft_coefficient__coeff_0__attr_\"angle\"',\n",
       "       'Signal__fft_coefficient__coeff_0__attr_\"imag\"',\n",
       "       'Signal__fft_coefficient__coeff_0__attr_\"real\"',\n",
       "       'Signal__fft_coefficient__coeff_10__attr_\"abs\"',\n",
       "       'Signal__fft_coefficient__coeff_10__attr_\"angle\"',\n",
       "       ...\n",
       "       'Signal__fft_coefficient__coeff_97__attr_\"imag\"',\n",
       "       'Signal__fft_coefficient__coeff_97__attr_\"real\"',\n",
       "       'Signal__fft_coefficient__coeff_98__attr_\"abs\"',\n",
       "       'Signal__fft_coefficient__coeff_98__attr_\"angle\"',\n",
       "       'Signal__fft_coefficient__coeff_98__attr_\"imag\"',\n",
       "       'Signal__fft_coefficient__coeff_98__attr_\"real\"',\n",
       "       'Signal__fft_coefficient__coeff_99__attr_\"abs\"',\n",
       "       'Signal__fft_coefficient__coeff_99__attr_\"angle\"',\n",
       "       'Signal__fft_coefficient__coeff_99__attr_\"imag\"',\n",
       "       'Signal__fft_coefficient__coeff_99__attr_\"real\"'],\n",
       "      dtype='object', length=400)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features1.columns[250:650]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Third approach - Using an Autoencoder DNN to find relevant features\n",
    "-------------------------------------------------------------------\n",
    "\n",
    "Since there are a significant number of features, and probably not all of them are relevant, there is a need to find the relevant features. This can be done using PCA ([Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis)), however this will only find linear relations. To find non-linear relations, it is possible to use [Autoencoder](https://en.wikipedia.org/wiki/Autoencoder) DNN's (Deep Neural Networks). To give some intuition on how this works, I'll briefly compare \"normal\" DNN's ([MLP](https://en.wikipedia.org/wiki/Multilayer_perceptron)) to autoencoders. \n",
    "\n",
    "An MLP's operation on an feature tensor $x$ can be defined as:\n",
    "\n",
    "$\\hat y=f_n(W_n(f_{n-1}(W_{n-1}( \\cdots f_1(W_1(x)) \\cdots )$\n",
    "\n",
    "With $\\hat y$ ,which is a tensor, as the prediction of the network, $f_i$ as the [activation function](https://en.wikipedia.org/wiki/Activation_function) of the $i_{th}$ layer and $W_i$ ,which is tensor, as the weights of the $i_{th}$ layer. Visually, you can imagine it like so:\n",
    "\n",
    "![](http://pubs.sciepub.com/ajmm/3/3/1/bigimage/fig5.png)\n",
    "\n",
    "Where the input is $x$ and the output is $\\hat y$. Now, imagine that the layers instead of expanding in the middle actuallly shrink, and then expand again? Like this:\n",
    "\n",
    "![](https://cdn-images-1.medium.com/max/1600/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)\n",
    "\n",
    "The network will encode the data in a non-linear fashion, and then decode it! \n",
    "\n",
    "Implementation:\n",
    "---------------\n",
    "\n",
    "I programed and trained an autoencoder on the data, using pytorch, an state of the art deep learning framework backed by Facebook, and then clustered it with some of the algorithms listed above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the Aoutoencoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "class autoencoder(nn.Module):\n",
    "    \n",
    "    def __init__(self,o_lin1_size,o_lin2_size,o_lin3_size):\n",
    "        super(autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(789, o_lin1_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(o_lin1_size, o_lin2_size),\n",
    "            nn.ReLU(True))\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(o_lin2_size, o_lin3_size),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(o_lin3_size, 789),\n",
    "            nn.Sigmoid())\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining hyperparameters and telling the computer to use the gpu if it is avaiable (per requirements):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "num_epochs = 2000\n",
    "batch_size = int(scaled_F.shape[0]/4)\n",
    "learning_rate = 1e-3\n",
    "    \n",
    "device=(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print (\"Using \"+device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_F=torch.tensor(scaled_F,dtype=torch.float).to(device)\n",
    "dataloader = DataLoader(tensor_F, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training model and finding optimal layer sizes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss().to(device)\n",
    "loss_tensor=np.empty((8,4,8,num_epochs))\n",
    "min_loss=np.inf\n",
    "parameters=None\n",
    "\n",
    "\n",
    "for lin_size1 in range(500,4001,500):\n",
    "    for lin_size2 in range(50,201,50):\n",
    "        for lin_size3 in range(500,4001,500):\n",
    "            clear_output(wait=True)\n",
    "            model = autoencoder(lin_size1,lin_size2,lin_size3).to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                for data in dataloader:\n",
    "                    # ===================forward=====================\n",
    "                    output = model(data)\n",
    "                    loss = criterion(output, data)\n",
    "                    loss_tensor[int((lin_size1-500)/500),int((lin_size2-50)/50),int((lin_size3-500)/500),epoch]=loss#loss in appropriate position\n",
    "                    #====================check if best version=======\n",
    "                    if loss<min_loss:\n",
    "                        min_loss=loss\n",
    "                        parameters=model.state_dict()\n",
    "                    # ===================backward====================\n",
    "                    optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                # ===================log========================\n",
    "                print('With lin_size1, lin_size2, lin_size3 equals: {},{},{}, epoch [{}/{}], loss:{:.4f}'\n",
    "                      .format(lin_size1, lin_size2, lin_size3, epoch + 1, num_epochs, loss.data))\n",
    "\n",
    "torch.save(parameters, './feature_autoencoder.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('./loss_tensor',loss_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters=torch.load('./feature_autoencoder.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000 100 4000\n"
     ]
    }
   ],
   "source": [
    "o_lin1_size=parameters['encoder.0.bias'].shape[0]\n",
    "o_lin2_size=parameters['encoder.2.bias'].shape[0]\n",
    "o_lin3_size=parameters['decoder.0.bias'].shape[0]\n",
    "\n",
    "print (o_lin1_size,o_lin2_size,o_lin3_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_model = autoencoder(o_lin1_size,o_lin2_size,o_lin3_size)\n",
    "opt_model.load_state_dict(parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Autoencoder to encode the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_F=opt_model.encoder(tensor_F.to('cpu')).detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_mean1=np.mean(ae_F[:760],axis=0)\n",
    "ae_mean2=np.mean(ae_F[760:],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying K-means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=2, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ae_kmeans=KMeans(n_clusters=2)\n",
    "ae_kmeans.fit(ae_F)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy of prediction in probabilities, and finding corresponding centers to groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9171052631578948 0.3183619550858653\n"
     ]
    }
   ],
   "source": [
    "center1=None\n",
    "center2=None\n",
    "\n",
    "prob1=np.sum(ae_kmeans.predict(ae_F[:760]))/760\n",
    "prob2=1-np.sum(ae_kmeans.predict(ae_F[760:]))/757\n",
    "\n",
    "if (prob1+prob2)>=(2-prob1-prob2):\n",
    "    print (prob1,prob2)\n",
    "    center1=ae_kmeans.cluster_centers_[1]\n",
    "    center2=ae_kmeans.cluster_centers_[0]\n",
    "else:\n",
    "    print (1-prob1,1-prob2)\n",
    "    center1=ae_kmeans.cluster_centers_[0]\n",
    "    center2=ae_kmeans.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8498e62831415881e50ba584625cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Encoded feature amplitude as a function of number of encdoed feature\")\n",
    "plt.ylabel(\"Encoded feature amplitude\")\n",
    "plt.xlabel(\"Number of encoded feature\")\n",
    "plt.plot(np.broadcast_to(np.arange(ae_F.shape[1]),(760,ae_F.shape[1])),ae_F[:760],'C1.',alpha=0.4)\n",
    "plt.plot(np.broadcast_to(np.arange(ae_F.shape[1]),(757,ae_F.shape[1])),ae_F[760:],'b.',alpha=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c65fba26289342648ebc4f73e8911146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Means of encoded feature amplitude as a function of number of encdoed feature\")\n",
    "plt.ylabel(\"Encoded feature amplitude\")\n",
    "plt.xlabel(\"Number of encoded feature\")\n",
    "plt.plot(range(ae_mean1.shape[0]),ae_mean1,'C1.',alpha=0.4)\n",
    "plt.plot(range(ae_mean2.shape[0]),ae_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Encoded feature amplitude as a function of number of encdoed feature\")\n",
    "plt.ylabel(\"Encoded feature amplitude\")\n",
    "plt.xlabel(\"Number of encoded feature\")\n",
    "plt.plot(range(ae_kmeans.cluster_centers_.shape[1]),ae_kmeans.cluster_centers_[0],'C1.',alpha=0.4)\n",
    "plt.plot(range(ae_kmeans.cluster_centers_.shape[1]),ae_kmeans.cluster_centers_[1],'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f27c95844f944c7ea460b875e15f9f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Kmean centers of encoded feature's comapred to their means\")\n",
    "plt.ylabel(\"Encoded feature amplitude\")\n",
    "plt.xlabel(\"Number of encoded feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'r.',alpha=0.5)\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.5)\n",
    "plt.plot(range(ae_mean1.shape[0]),ae_mean1,'C1.',alpha=0.4)\n",
    "plt.plot(range(ae_mean2.shape[0]),ae_mean2,'b.',alpha=0.2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76963b89aacc485e8eb2707e6a5b17a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Kmean center compared to mean of encoded feature's barcode1\")\n",
    "plt.ylabel(\"Encoded feature amplitude\")\n",
    "plt.xlabel(\"Number of encoded feature\")\n",
    "plt.plot(range(center1.shape[0]),center1,'r.',alpha=1)\n",
    "plt.plot(range(ae_mean1.shape[0]),ae_mean1,'C1.',alpha=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Elad\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py:537: RuntimeWarning: More than 20 figures have been opened. Figures created through the pyplot interface (`matplotlib.pyplot.figure`) are retained until explicitly closed and may consume too much memory. (To control this warning, see the rcParam `figure.max_open_warning`).\n",
      "  max_open_warning, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf349b68bc28479ca226a3909f5da1fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FigureCanvasNbAgg()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "\n",
    "plt.title(\"Kmean center compared to mean of encoded feature's barcode2\")\n",
    "plt.ylabel(\"Encoded feature amplitude\")\n",
    "plt.xlabel(\"Number of encoded feature\")\n",
    "plt.plot(range(center2.shape[0]),center2,'g.',alpha=0.6)\n",
    "plt.plot(range(ae_mean2.shape[0]),ae_mean2,'b.',alpha=0.4)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conclusions:\n",
    "------------\n",
    "\n",
    "There appears to be a slight improvement over clustering it normally, not done yet.\n",
    "\n",
    "An Interesting Obversation:\n",
    "---------------------------\n",
    "\n",
    "If you change the clusters generated by multiplying by -1 better results emerge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_t=KMeans(n_clusters=2)\n",
    "kmeans_t.fit(F)\n",
    "kmeans_t.cluster_centers_[0]=-scaled_kmeans.cluster_centers_[0]\n",
    "kmeans_t.cluster_centers_[1]=-scaled_kmeans.cluster_centers_[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539473684210526 0.5178335535006605\n"
     ]
    }
   ],
   "source": [
    "prob1=np.sum(kmeans_t.predict(scaled_F[:760]))/760\n",
    "prob2=1-np.sum(kmeans_t.predict(scaled_F[760:]))/757\n",
    "\n",
    "if (prob1+prob2)>=(2-prob1-prob2):\n",
    "    print (prob1,prob2)\n",
    "else:\n",
    "    print (1-prob1,1-prob2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional approaches:\n",
    "------------------------\n",
    "\n",
    "1.Unsupervised clustering via deep learning based on this [paper](https://arxiv.org/pdf/1801.07648.pdf), which contains various methods of doing so.\n",
    "\n",
    "2.Forgoing the unsupervised restriction and using boosting methods to create an accurate classifier.\n",
    "\n",
    "3.This [paper](https://www.biorxiv.org/content/biorxiv/early/2018/11/06/463463.full.pdf)\n",
    "\n",
    "Other important resources:\n",
    "---------------------------\n",
    "[Github page comparing different basecallers](https://github.com/rrwick/Basecalling-comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
